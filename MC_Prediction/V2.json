{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
      "kernelspec": {
        "display_name": "Python 3",
        "language": "python",
        "name": "python3"
      },
      "language_info": {
        "name": "python",
        "version": ""
      }
    },
    "cells": [
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "# BNP Paribas Stock Price HMM Analysis\n",
          "\n",
          "This notebook:\n",
          "1. Reads and cleans BNP Paribas stock price data.\n",
          "2. Computes log returns.\n",
          "3. Fits a Gaussian Hidden Markov Model (HMM) with `n_components=10` hidden states.\n",
          "4. Stores the learned model in Neo4j (states, transitions).\n",
          "5. Demonstrates a function for forecasting log returns.\n",
          "6. Finally, adds simulation and comparison with actual data for the first 100 observations.\n",
          "\n",
          "Comments are added in each cell to clarify the process."
        ]
      },
      {
        "cell_type": "code",
        "metadata": {
          "executionInfo": {}
        },
        "source": [
          "# %%\n",
          "# Step 1: Load libraries and read CSV\n",
          "import pandas as pd\n",
          "import numpy as np\n",
          "\n",
          "# Read BNP Paribas data\n",
          "data_bnp = pd.read_csv('../data/BNPPA.csv')\n",
          "\n",
          "# Convert 'Date' column to datetime\n",
          "data_bnp['Date'] = pd.to_datetime(data_bnp['Date'])\n",
          "\n",
          "# Sort values by date\n",
          "data_bnp.sort_values('Date', inplace=True)\n",
          "\n",
          "# Reset index after sorting\n",
          "data_bnp.reset_index(drop=True, inplace=True)\n",
          "\n",
          "# 1) Filter invalid or missing close prices\n",
          "data_bnp = data_bnp[data_bnp['Close'].notna()]      # remove rows missing close\n",
          "data_bnp = data_bnp[data_bnp['Close'] > 0]          # remove zero or negative\n",
          "\n",
          "# 2) Compute log prices & returns\n",
          "data_bnp['LogClose'] = np.log(data_bnp['Close'])\n",
          "data_bnp['LogRet']   = data_bnp['LogClose'].diff()\n",
          "\n",
          "# 3) Replace inf and drop NaNs that result (e.g., from diff of the first row)\n",
          "data_bnp.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
          "data_bnp.dropna(subset=['LogRet'], inplace=True)\n",
          "\n",
          "# Display final cleaned dataframe\n",
          "data_bnp"
        ],
        "outputs": []
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "# %%\n",
          "# Final check and transform observations into 2D array for HMM\n",
          "observations = data_bnp['LogRet'].values.reshape(-1, 1)\n",
          "if np.isnan(observations).any() or np.isinf(observations).any():\n",
          "    raise ValueError(\"Observations still contain NaN or Inf - check data pipeline.\")\n",
          "\n",
          "observations"
        ],
        "outputs": []
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "# %%\n",
          "# Connect to Neo4j and clear any existing data\n",
          "from py2neo import Graph\n",
          "# Make sure to replace the auth with your correct credentials\n",
          "graph = Graph(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"))\n",
          "\n",
          "# Clear existing graph data\n",
          "graph.run(\"MATCH (n) DETACH DELETE n\")\n"
        ],
        "outputs": []
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "# %%\n",
          "# Import hmmlearn and create the GaussianHMM\n",
          "from hmmlearn import hmm\n",
          "\n",
          "# Let's choose 10 hidden states\n",
          "n_components = 10\n",
          "\n",
          "# Instantiate a GaussianHMM\n",
          "model = hmm.GaussianHMM(\n",
          "    n_components=n_components,\n",
          "    covariance_type='full',  # 'full' means a full covariance matrix\n",
          "    n_iter=100,             # Maximum number of EM iterations\n",
          "    random_state=42         # For reproducibility\n",
          ")\n",
          "\n",
          "# Fit (train) the model to the data using the Baum-Welch algorithm\n",
          "model.fit(observations)\n",
          "\n",
          "print(\"Model has been trained.\")"
        ],
        "outputs": []
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "# %%\n",
          "# Decode hidden states using the Viterbi algorithm\n",
          "# hidden_states[i] will be the most likely hidden state index on day i\n",
          "\n",
          "hidden_states = model.predict(observations)\n",
          "\n",
          "# Extract important parameters\n",
          "start_probs = model.startprob_        # shape = (n_components,)\n",
          "trans_probs = model.transmat_         # shape = (n_components, n_components)\n",
          "means = model.means_.flatten()        # shape = (n_components,)\n",
          "covars = model.covars_                # shape depends on covariance_type\n",
          "\n",
          "# Display the transition matrix, rounded to 3 decimals\n",
          "transition_matrix = model.transmat_\n",
          "transition_matrix_3dec = np.round(transition_matrix, 3)\n",
          "print(\"Transition Matrix (3 decimals):\")\n",
          "print(transition_matrix_3dec)"
        ],
        "outputs": []
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "# %%\n",
          "# 5. Save the HMM in Neo4j\n",
          "#\n",
          "# A) Create a parent node for the entire HMM.\n",
          "# B) Create nodes for each hidden state and store mean, variance, start prob.\n",
          "# C) Create relationships representing transition probabilities.\n",
          "\n",
          "graph.run(\"MATCH (n) DETACH DELETE n\")\n",
          "hmm_name = \"BNP_HMM\"\n",
          "create_hmm_query = f\"\"\"\n",
          "MERGE (h:HMM {{name: $hmm_name}})\n",
          "ON CREATE SET h.description = \"GaussianHMM with {n_components} hidden states\"\n",
          "RETURN h\n",
          "\"\"\"\n",
          "# Create or update the parent HMM node\n",
          "graph.run(create_hmm_query, hmm_name=hmm_name)\n",
          "\n",
          "# B) Create nodes for each state\n",
          "for i in range(n_components):\n",
          "    # For 'full' covariance and 1D data, covars[i] is a 1x1 matrix.\n",
          "    # We'll store just the diagonal (variance) as a float.\n",
          "    if covars[i].ndim > 1:\n",
          "        var_value = covars[i].diagonal().mean()\n",
          "    else:\n",
          "        var_value = covars[i]\n",
          "\n",
          "    create_state_query = f\"\"\"\n",
          "    MERGE (s:State {{hmm_name: $hmm_name, state_index: $state_index}})\n",
          "    ON CREATE SET\n",
          "      s.mean = $mean,\n",
          "      s.variance = $variance,\n",
          "      s.start_prob = $start_prob\n",
          "    RETURN s\n",
          "    \"\"\"\n",
          "\n",
          "    graph.run(\n",
          "        create_state_query,\n",
          "        hmm_name=hmm_name,\n",
          "        state_index=i,\n",
          "        mean=float(means[i]),\n",
          "        variance=float(var_value),\n",
          "        start_prob=float(start_probs[i])\n",
          "    )\n",
          "\n",
          "# C) Create relationships for transition probabilities\n",
          "for i in range(n_components):\n",
          "    for j in range(n_components):\n",
          "        prob_ij = float(trans_probs[i, j])\n",
          "        create_rel_query = f\"\"\"\n",
          "        MATCH (s1:State {{hmm_name: $hmm_name, state_index: $i}}),\n",
          "              (s2:State {{hmm_name: $hmm_name, state_index: $j}})\n",
          "        MERGE (s1)-[r:TRANSITION_TO {{prob: $prob_ij}}]->(s2)\n",
          "        RETURN r\n",
          "        \"\"\"\n",
          "        graph.run(create_rel_query, hmm_name=hmm_name, i=i, j=j, prob_ij=prob_ij)\n",
          "\n",
          "print(\"HMM parameters have been stored in Neo4j.\")"
        ],
        "outputs": []
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "# %%\n",
          "# 6. Posterior probabilities & Forecast function\n",
          "#\n",
          "# 'predict_proba()' gives the posterior state probabilities at each time step.\n",
          "# Then we define a forecast function that uses a weighted average of means.\n",
          "\n",
          "# Retrieve posterior probabilities for each day/state\n",
          "posterior_probs = model.predict_proba(observations)\n",
          "\n",
          "def forecast_log_returns(start_probs, transmat, means, steps=5):\n",
          "    \"\"\"\n",
          "    start_probs: posterior probability distribution over states for the last known day\n",
          "    transmat: transition matrix from the fitted HMM\n",
          "    means: array of shape (n_components,) - mean log return per state\n",
          "    steps: how many steps ahead to forecast\n",
          "\n",
          "    This function evolves the distribution over states using the Markov chain.\n",
          "    Then at each step, computes a weighted average of the state's mean log returns.\n",
          "    \"\"\"\n",
          "    # Copy to avoid mutating the input\n",
          "    dist = start_probs.copy()\n",
          "    forecasts = []\n",
          "\n",
          "    for step in range(steps):\n",
          "        # Weighted average log return for the current distribution over states\n",
          "        forecast_r = np.sum(dist * means)\n",
          "        forecasts.append(forecast_r)\n",
          "\n",
          "        # Evolve the distribution by 1 time step via matrix multiplication\n",
          "        dist = dist @ transmat\n",
          "\n",
          "    return forecasts\n",
          "\n",
          "# Example usage: predict 5-day-ahead average log returns based on the final distribution\n",
          "last_day_probs = posterior_probs[-1, :]\n",
          "multi_step_logret = forecast_log_returns(\n",
          "    start_probs=last_day_probs,\n",
          "    transmat=model.transmat_,\n",
          "    means=model.means_.flatten(),\n",
          "    steps=5\n",
          ")\n",
          "print(\"Predicted log returns for the next 5 days:\", multi_step_logret)"
        ],
        "outputs": []
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "# %%\n",
          "# 7. Simulate the first 100 observations and compare vs actual data\n",
          "#\n",
          "# We'll do a generative simulation of the HMM for 100 steps, starting\n",
          "# from a sampled initial state (according to startprob_). We'll then\n",
          "# compare that simulated price path with the actual first 100 day prices.\n",
          "\n",
          "import matplotlib.pyplot as plt\n",
          "import math\n",
          "\n",
          "def simulate_hmm(model, n=100):\n",
          "    \"\"\"\n",
          "    Generates a synthetic sequence of hidden states and observations\n",
          "    from a trained HMM.\n",
          "\n",
          "    Parameters:\n",
          "        model: a fitted hmm.GaussianHMM instance\n",
          "        n: number of time steps to simulate\n",
          "\n",
          "    Returns:\n",
          "        sim_states: array of length n with the sampled hidden states\n",
          "        sim_obs:    array of length n with the sampled log returns\n",
          "    \"\"\"\n",
          "    # Extract key parameters\n",
          "    start_probs = model.startprob_       # shape: (n_components,)\n",
          "    trans_probs = model.transmat_        # shape: (n_components, n_components)\n",
          "    means = model.means_                 # shape: (n_components, n_features)\n",
          "    covars = model.covars_               # depends on covariance_type\n",
          "\n",
          "    n_states = model.n_components\n",
          "\n",
          "    # 1) Sample initial hidden state from the model's start probabilities\n",
          "    state = np.random.choice(range(n_states), p=start_probs)\n",
          "    sim_states = [state]\n",
          "    sim_obs = []\n",
          "\n",
          "    # 2) Draw the first observation from the state's Gaussian\n",
          "    if model.covariance_type == 'full':\n",
          "        std_dev = math.sqrt(covars[state, 0, 0])\n",
          "    else:  # 'diag' or other type\n",
          "        std_dev = math.sqrt(covars[state, 0])\n",
          "\n",
          "    obs = np.random.normal(loc=means[state, 0], scale=std_dev)\n",
          "    sim_obs.append(obs)\n",
          "\n",
          "    # 3) Iteratively sample next hidden states and observations\n",
          "    for _ in range(n - 1):\n",
          "        # Sample next state based on transition probabilities of the current state\n",
          "        state = np.random.choice(range(n_states), p=trans_probs[state])\n",
          "        sim_states.append(state)\n",
          "\n",
          "        # Sample observation from the chosen state's Gaussian\n",
          "        if model.covariance_type == 'full':\n",
          "            std_dev = math.sqrt(covars[state, 0, 0])\n",
          "        else:\n",
          "            std_dev = math.sqrt(covars[state, 0])\n",
          "\n",
          "        obs = np.random.normal(loc=means[state, 0], scale=std_dev)\n",
          "        sim_obs.append(obs)\n",
          "\n",
          "    return np.array(sim_states), np.array(sim_obs)\n",
          "\n",
          "# --- Perform the simulation ---\n",
          "sim_length = 100\n",
          "sim_states, sim_obs = simulate_hmm(model, n=sim_length)\n",
          "\n",
          "# Convert simulated log returns to prices\n",
          "# We'll start from the same initial price as the actual data on day 0\n",
          "actual_prices_100 = data_bnp['Close'].values[:sim_length]\n",
          "initial_price = actual_prices_100[0]\n",
          "\n",
          "simulated_prices = [initial_price]\n",
          "for i in range(1, sim_length):\n",
          "    # Price_t = Price_(t-1) * e^(sim_obs[i])\n",
          "    next_price = simulated_prices[-1] * np.exp(sim_obs[i])\n",
          "    simulated_prices.append(next_price)\n",
          "\n",
          "# --- Plot Actual vs Simulated (Generative) ---\n",
          "plt.figure(figsize=(10, 6))\n",
          "plt.plot(range(sim_length), actual_prices_100, label='Actual Price (first 100 days)', color='blue')\n",
          "plt.plot(range(sim_length), simulated_prices, label='Simulated Price from HMM', color='orange', linestyle='--')\n",
          "plt.title(\"Actual vs. HMM-Simulated Prices (First 100 Days)\")\n",
          "plt.xlabel(\"Time Index (days)\")\n",
          "plt.ylabel(\"Price\")\n",
          "plt.legend()\n",
          "plt.show()\n"
        ],
        "outputs": []
      },
      {
        "cell_type": "code",
        "metadata": {},
        "source": [
          "# %%\n",
          "# 8. (Optional) In-Sample Prediction Approach for First 100 Days\n",
          "# -------------------------------------------------------------\n",
          "# Instead of purely simulating, you can see how well the HMM does in-sample\n",
          "# by decoding states from the actual log returns, then using each day's\n",
          "# hidden state's mean to predict the next day's return.\n",
          "\n",
          "# We'll slice the first 100 log returns\n",
          "observations_100 = observations[:100]\n",
          "hidden_states_100 = model.predict(observations_100)\n",
          "in_sample_prices = np.zeros(100)\n",
          "actual_prices_100 = data_bnp['Close'].values[:100]\n",
          "\n",
          "# Initialize the predicted price to be the actual price on day 0\n",
          "in_sample_prices[0] = actual_prices_100[0]\n",
          "\n",
          "# Reconstruct predicted price path\n",
          "for t in range(1, 100):\n",
          "    # Use the hidden state of the previous day to get mean log return\n",
          "    st = hidden_states_100[t-1]\n",
          "    mu_t = model.means_[st, 0]\n",
          "    in_sample_prices[t] = in_sample_prices[t-1] * np.exp(mu_t)\n",
          "\n",
          "# Plot actual vs. in-sample predicted\n",
          "plt.figure(figsize=(10, 6))\n",
          "plt.plot(range(100), actual_prices_100, label='Actual Price (first 100 days)', color='blue')\n",
          "plt.plot(range(100), in_sample_prices, label='In-sample Predicted Price (HMM)', color='red', linestyle='--')\n",
          "plt.title(\"Actual vs. In-Sample Predicted Prices (First 100 Days)\")\n",
          "plt.xlabel(\"Time Index (days)\")\n",
          "plt.ylabel(\"Price\")\n",
          "plt.legend()\n",
          "plt.show()\n"
        ],
        "outputs": []
      }
    ]
  }
  